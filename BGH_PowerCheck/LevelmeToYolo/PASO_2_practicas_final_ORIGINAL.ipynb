{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4866,"status":"ok","timestamp":1733068864795,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"Tpywp1FCzym1","outputId":"a9d49309-7c7f-4d2c-819c-2708c2bf590a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.39 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 32.9/112.6 GB disk)\n"]}],"source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxuCHy8az42t"},"outputs":[],"source":["import os\n","import shutil\n","import random\n","from tqdm.notebook import tqdm  # Correcta importaci√≥n para usar tqdm en Jupyter Notebook.\n","from google.colab import drive  # Correcto para interactuar con Google Drive en Google Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2624,"status":"ok","timestamp":1733068882224,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"SneQYt_Fz6vO","outputId":"b8b56a19-a546-4fc6-f755-49c47c9ec3f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"]}],"source":["!pip install tqdm --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2722,"status":"ok","timestamp":1733068886269,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"BWBMQRA2z9Rc","outputId":"435db106-1a6a-4191-f308-27772667e0a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1733068888707,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"UgKJhYIMz_f0","outputId":"d8ccb799-f5f7-4b66-c19e-550a32c1e4e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["['images', 'labels', 'test', 'dataset.yaml']\n"]}],"source":["import os\n","\n","# Listar archivos en el directorio YOLODataset\n","#image_dir = '/content/drive/MyDrive/fotos etiquetadas/YOLODataset'\n","image_dir = '/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset'\n","print(os.listdir(image_dir))"]},{"cell_type":"markdown","metadata":{"id":"MNE0Z91h0ByF"},"source":["Predicci√≥n\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6480,"status":"ok","timestamp":1733068897715,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"JDKc9-uq0D5Q","outputId":"1b4492e8-f83c-479b-c82f-167e6d6784f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.39)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.12)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":548,"status":"ok","timestamp":1733068900503,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"pcAdcLM90g9Q","outputId":"5388d20e-24ae-44c8-e686-3a543667f4b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Divisi√≥n completada: 80% entrenamiento y 20% validaci√≥n.\n"]}],"source":["import os\n","import random\n","import shutil\n","\n","# Definir las rutas de tus carpetas\n","image_dir = \"/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/images\"  # Ruta de las im√°genes\n","label_dir = \"/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/labels\"  # Ruta de las etiquetas\n","\n","train_image_dir = os.path.join(image_dir, 'train')\n","val_image_dir = os.path.join(image_dir, 'val')\n","train_label_dir = os.path.join(label_dir, 'train')\n","val_label_dir = os.path.join(label_dir, 'val')\n","\n","# Crear las carpetas si no existen\n","os.makedirs(train_image_dir, exist_ok=True)\n","os.makedirs(val_image_dir, exist_ok=True)\n","os.makedirs(train_label_dir, exist_ok=True)\n","os.makedirs(val_label_dir, exist_ok=True)\n","\n","# Obtener la lista de todas las im√°genes\n","images = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","# Dividir en 80% entrenamiento y 20% validaci√≥n\n","random.shuffle(images)  # Barajar las im√°genes para asegurar una distribuci√≥n aleatoria\n","split_idx = int(len(images) * 0.8)  # El 80% de las im√°genes\n","\n","train_images = images[:split_idx]\n","val_images = images[split_idx:]\n","\n","# Mover las im√°genes y las etiquetas a las carpetas correspondientes\n","for img in train_images:\n","    # Mover imagen\n","    shutil.move(os.path.join(image_dir, img), os.path.join(train_image_dir, img))\n","\n","    # Mover la etiqueta correspondiente\n","    label = img.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n","    shutil.move(os.path.join(label_dir, label), os.path.join(train_label_dir, label))\n","\n","for img in val_images:\n","    # Mover imagen\n","    shutil.move(os.path.join(image_dir, img), os.path.join(val_image_dir, img))\n","\n","    # Mover la etiqueta correspondiente\n","    label = img.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n","    shutil.move(os.path.join(label_dir, label), os.path.join(val_label_dir, label))\n","\n","print(\"Divisi√≥n completada: 80% entrenamiento y 20% validaci√≥n.\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v9SCM1F90HXH","executionInfo":{"status":"ok","timestamp":1733069011468,"user_tz":180,"elapsed":21703,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"}},"outputId":"7bd1a08c-db15-42a1-a1c7-67f390af434b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.39 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/dataset.yaml, epochs=500, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=disk, device=0, workers=8, project=YOLOv8, name=yolov8n2, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=yolov8n.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=ultralytics/assets/, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, label_smoothing=0.0, save_dir=YOLOv8/yolov8n2\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir YOLOv8/yolov8n2', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=13\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    753847  ultralytics.nn.modules.head.Detect           [13, [64, 128, 256]]          \n","Model summary: 225 layers, 3,013,383 parameters, 3,013,367 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/labels/train.cache... 99 images, 0 backgrounds, 0 corrupt: 100% 99/99 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB Disk): 100% 99/99 [00:00<00:00, 3179.04it/s]\n","/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/labels/val.cache... 11 images, 0 backgrounds, 0 corrupt: 100% 11/11 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB Disk): 100% 11/11 [00:00<00:00, 409.34it/s]\n","WARNING ‚ö†Ô∏è 'label_smoothing' is deprecated and will be removed in in the future.\n","Plotting labels to YOLOv8/yolov8n2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 969, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 805, in train\n","    self.trainer.train()\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 207, in train\n","    self._do_train(world_size)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 322, in _do_train\n","    self._setup_train(world_size)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 314, in _setup_train\n","    self.resume_training(ckpt)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 735, in resume_training\n","    assert start_epoch > 0, (\n","AssertionError: yolov8n.pt training to 500 epochs is finished, nothing to resume.\n","Start a new training without resuming, i.e. 'yolo train model=yolov8n.pt'\n"]}],"source":["#!yolo train data=\"/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/dataset.yaml\" model=yolov8n.pt epochs=2\n","#!yolo train data=\"/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/dataset.yaml\" model=yolov8n.pt epochs=2 project=\"/content/drive/MyDrive/YOLO_runs\"\n","\n","!yolo train \\\n","    data=\"/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/dataset.yaml\" \\\n","    model=yolov8n.pt \\\n","    epochs=500 \\\n","    project=\"/content/drive/MyDrive/Practicas_2_2024_BGH/YOLO_runs\" \\\n","    name=\"placa_detector500\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fc8W_6TJ0Ilf"},"outputs":[],"source":["# Buscar el archivo .pt en el entorno local\n","search_dir = '/content/runs/detect/'\n","for root, dirs, files in os.walk(search_dir):\n","    if 'best.pt' in files:\n","        print(f\"Archivo encontrado en: {root}/best.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2794,"status":"ok","timestamp":1732747682421,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"0YaELLkT0Pg1","outputId":"41eeff06-6143-48a9-f3b9-c715921567b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.26.4)\n"]}],"source":["pip install opencv-contrib-python"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":135010,"status":"ok","timestamp":1732747819063,"user":{"displayName":"Federico D'Oliveira","userId":"15566674850354112284"},"user_tz":180},"id":"ywZv0D5e0P-k","outputId":"308ce786-bef2-4600-820e-2f18cb85ca41"},"outputs":[],"source":["from ultralytics import YOLO\n","import os\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","# Cargar el modelo entrenado\n","model = YOLO(\"/content/yolov8n.pt\")\n","#model = YOLO(\"/content/runs/detect/train/weights/best.pt\")\n","\n","# Ruta de la carpeta con las im√°genes de test\n","test_images_path = \"/content/drive/MyDrive/Practicas_2_2024_BGH/fotos etiquetadas/YOLODataset/test\"\n","\n","# Definir las clases esperadas\n","expected_classes = ['N IN 1', 'NTC 1', 'C 496', 'CN 12', 'CN 19', 'C 497', 'C 498', 'CN 15', 'CN 14', 'C 259', 'C 251', 'CN 18', 'SW 1']\n","\n","# Para almacenar las detecciones \"Good\" y \"No Good\"\n","good_detections = []\n","no_good_detections = []\n","\n","# Procesar las im√°genes\n","for img_name in os.listdir(test_images_path):\n","    img_path = os.path.join(test_images_path, img_name)\n","\n","    # Leer la imagen\n","    img = cv2.imread(img_path)\n","\n","    # Realizar la inferencia\n","    results = model(img_path)\n","\n","    # Obtener las predicciones\n","    predictions = results[0].boxes\n","    detected_classes = results[0].names\n","\n","    # Verificar las clases detectadas\n","    detected_class_ids = predictions.cls.tolist()  # Los IDs de las clases detectadas\n","    detected_class_names = [detected_classes[int(class_id)] for class_id in detected_class_ids]\n","\n","    # Calcular las clases faltantes\n","    detected_classes_set = set(detected_class_names)\n","    missing_classes = [cls for cls in expected_classes if cls not in detected_classes_set]\n","\n","    # Calcular el porcentaje de faltantes\n","    missing_percentage = (len(missing_classes) / len(expected_classes)) * 100\n","\n","    # Dibujar las cajas de detecci√≥n en la imagen\n","    for box, class_name in zip(predictions.xyxy.tolist(), detected_class_names):\n","        if class_name in detected_class_names:\n","            x1, y1, x2, y2 = map(int, box)\n","            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","            cv2.putText(img, class_name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","    # Mostrar la imagen con recuadros\n","    print(f\"Imagen: {img_name}\")\n","    print(f\"Componentes faltantes: {missing_classes}\")\n","    print(f\"Porcentaje de faltantes: {missing_percentage:.2f}%\\n\")\n","\n","    # Mostrar la imagen con las detecciones y faltantes visualmente\n","    cv2_imshow(img)  # Mostrar la imagen con OpenCV en Colab\n","\n","    # Almacenar las detecciones\n","    if missing_percentage == 0:\n","        good_detections.append((img_name, detected_class_names))\n","    else:\n","        no_good_detections.append((img_name, missing_classes, missing_percentage))\n","\n","# Imprimir un resumen de las detecciones \"Good\" y \"No Good\"\n","print(\"Detecciones Good:\")\n","for good in good_detections:\n","    print(f\"Imagen: {good[0]}, Clases detectadas: {good[1]}\")\n","\n","print(\"\\nDetecciones No Good:\")\n","for no_good in no_good_detections:\n","    print(f\"Imagen: {no_good[0]}, Componentes faltantes: {no_good[1]}, Porcentaje de faltantes: {no_good[2]:.2f}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}